{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary modules \n",
    "import numpy as np \n",
    "import imutils \n",
    "import pickle\n",
    "import cv2 \n",
    "import os \n",
    "import tensorflow as tf \n",
    "from imutils import paths \n",
    "from sklearn.svm import SVC   \n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler \n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting path to the dataset and model directory \n",
    "img_dir = \"dataset\" \n",
    "embeddings = \"models/embeddings.pickle\"\n",
    "detector_model = \"models/face_detection_model\" \n",
    "embedding_model = \"models/embeddingModel.t7\" \n",
    "recognize_model = \"models/output/recognizer.pickle\" \n",
    "label_model = \"models/output/le.pickle\"\n",
    "X_encoder = \"models/output/encoder.h5\"\n",
    "\n",
    "# Setting the confidence value \n",
    "confidence_value = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk \n",
    "proto_path = os.path.join(detector_model, \"deploy.prototxt\")\n",
    "model_path = os.path.join(detector_model, \"res10.caffemodel\")\n",
    "\n",
    "# Creating the detector \n",
    "detector = cv2.dnn.readNetFromCaffe(proto_path, model_path)\n",
    "\n",
    "# Loading the serialized face embeddings model from disk \n",
    "embedder = cv2.dnn.readNetFromTorch(embedding_model) \n",
    "\n",
    "# Specifying the path to the images dataset\n",
    "# Initialize our list of extracted facial embeddings that cooresponds to the \n",
    "# People names. \n",
    "image_path = list(paths.list_images(img_dir))\n",
    "known_embeddings = []\n",
    "known_names = []\n",
    "total = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serialized encodings:  1128\n"
     ]
    }
   ],
   "source": [
    "# Creating a loop to loop through the images in the specified path. \n",
    "# load the image, resize it to have a width of 600 pixels and then grab the image dimensions. \n",
    "# Construct a blob from the image, apply opencv deep learning face detector to localize the face \n",
    "# And ensure that at least one face was found. \n",
    "for (i, image) in enumerate(image_path): \n",
    "    label = image.split(\"/\")[-2]\n",
    "    img = cv2.imread(image) \n",
    "    img = imutils.resize(img, width=600) \n",
    "    # Getting the height and width of the image \n",
    "    (h, w) = img.shape[:2]\n",
    "    # Blob construction \n",
    "    image_blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1.0, \n",
    "                                      (300, 300), (104.0, 177.0, 123.0), swapRB=False, crop=False)\n",
    "     \n",
    "    # Creating an instance of the detector object by calling the setInput method to \n",
    "    # take in the image_blob values \n",
    "    detector.setInput(image_blob) \n",
    "    detections = detector.forward() \n",
    "    \n",
    "    # If the length for detections is greater than one, perfom the following below \n",
    "    if len(detections) > 0:\n",
    "        i = np.argmax(detections[0, 0, :, 2])\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        \n",
    "        # Ensure that the detections with the larges probability also means our minimum test \n",
    "        # Thus filtering off weak detections. \n",
    "        if confidence >= confidence_value: \n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype('int')\n",
    "            \n",
    "            # Extract the face Region of intreast ROI and grab the ROI dimensions \n",
    "            face = img[startX:endY, startX:endX]\n",
    "            (fH, fW) = face.shape[:2]\n",
    "            \n",
    "            # Ensure that the face width and height are sufficiently large. \n",
    "            if fW < 20 or fH < 20: \n",
    "                continue \n",
    "                \n",
    "            # Construct a blob for the face ROI, then pass the blob through our embedding to obtain the 128-d dimensions \n",
    "            # Of the face \n",
    "            face_blob = cv2.dnn.blobFromImage(img, 1.0 / 255, (96, 96), (0, 0, 0), swapRB=True, \n",
    "                                             crop=False)\n",
    "            \n",
    "            # Getting the embeddings \n",
    "            embedder.setInput(face_blob) \n",
    "            vector = embedder.forward() \n",
    "            \n",
    "            # Adding the name of the person + corresponding face embeddngs to their\n",
    "            # Respective lists \n",
    "            known_names.append(label)\n",
    "            known_embeddings.append(vector.flatten())\n",
    "            total += 1 \n",
    "\n",
    "            \n",
    "# Dumping the facial embeddings and its respective names to disk \n",
    "print(\"Serialized encodings: \", total)\n",
    "data = {'embeddings': known_embeddings, 'names': known_names}\n",
    "\n",
    "# Saving the data \n",
    "f = open(embeddings, 'wb')\n",
    "f.write(pickle.dumps(data)) \n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the facial recognition model to produce the actual face recognition \n",
    "lb = LabelEncoder() \n",
    "y = lb.fit_transform(known_names)\n",
    "\n",
    "# Using SVC \n",
    "model = SVC(C=1.0, kernel=\"linear\", probability=True) \n",
    "model.fit(data['embeddings'], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the actual face recognition model to disk \n",
    "f = open(recognize_model, \"wb\")\n",
    "f.write(pickle.dumps(model))\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dumping the encoder \n",
    "f = open(label_model, \"wb\")\n",
    "f.write(pickle.dumps(lb))\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the standard scaler encoder  \n",
    "# f = open(X_encoder, \"wb\")\n",
    "# f.write(pickle.d2umps(encoder))\n",
    "# f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Converting the encoded y-output features into categorical data for easy modelling \n",
    "# y_encoded = to_categorical(y, num_classes=len(lb.classes_))\n",
    "\n",
    "# # Scaling the input features \n",
    "# encoder = StandardScaler() \n",
    "# X = np.array(known_embeddings)\n",
    "# X = encoder.fit_transform(X) \n",
    "\n",
    "\n",
    "\n",
    "# Building the model \n",
    "# def DefineModel(input_dim): \n",
    "#     model = Sequential() \n",
    "#     model.add(Dense(32, input_dim=input_dim, activation=\"relu\"))\n",
    "#     model.add(Dense(8, activation=\"relu\"))\n",
    "#     model.add(Dense(2, activation=\"sigmoid\"))\n",
    "\n",
    "#     # Compiling the model \n",
    "#     model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "    \n",
    "#     # Returning the model \n",
    "#     return model \n",
    "\n",
    "# dim = X.shape[1]\n",
    "\n",
    "# # \n",
    "# num_class = len(lb.classes_)\n",
    "\n",
    "# # Creating the model \n",
    "# model = DefineModel(dim) \n",
    "\n",
    "# # Displaying the summary of the model \n",
    "# model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model \n",
    "# H = model.fit(X, y_encoded, epochs = 200, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict_proba(X[20].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the actual face recognition model and label encoder \n",
    "# model to disk \n",
    "# model.save_weights(recognize_model)\n",
    "\n",
    "# # Dumping the encoder \n",
    "# f = open(label_model, \"wb\")\n",
    "# f.write(pickle.dumps(lb))\n",
    "# f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['chinedu', 'unknown'], dtype='<U7')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[20].reshape(1, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('ml': conda)",
   "language": "python",
   "name": "python361064bitmlconda75a28202137d45298163405898c2e2d1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
